{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72f03dd",
   "metadata": {},
   "source": [
    "## Initial Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b085ea",
   "metadata": {},
   "source": [
    "Our initial proposed idea was to use Topic Models to enhance the performance of a spam/ham classifier on the Enron email dataset and in doing so compare the performance increase (if any) that different topic models gave. The general idea was to use a Topic Model to assign each document and create a `topic` feature vector to add to the original dataset and run the classifier on.\n",
    "\n",
    "We hoped that this would give some intuition as to what each topic corresponds to and enable us to measure how informative each Topic Model was through the comparison of performance increase and feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fb95b2",
   "metadata": {},
   "source": [
    "## Meeting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea840b15",
   "metadata": {},
   "source": [
    "#### Re: Initial Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf5af1e",
   "metadata": {},
   "source": [
    "The proposed approach above brings rise to some questions that are important to consider and address, namely:\n",
    " - What features should the original classifier take as inputs? \n",
    " - How do we engineer these features given the plain text format of our dataset?\n",
    " - What happens if the features we create add a lot of noise that the classifier focuses too much on and distorts the comparison of the models?\n",
    " \n",
    "These are mainly feature-engineering questions and are not directly related to the scope of this project and so it is important to decide whether spending (too much) time on this is useful or not. As a result, it may be worth trying this very briefly and if creating features takes too long, abandoning this approach and focusing solely on a Topic/Document Model comparison approach instead.\n",
    "\n",
    "#### Features suggested that we could try (are these enough?):\n",
    "- Word count\n",
    "- Count of capital letters\n",
    "    - Count of consecutive capital letters\n",
    "- Appearance/count of 're:' or 'fw:' in the emails\n",
    "- Misspelling count (Coursebook Block 7 should have an Appendix for this)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b714f59e",
   "metadata": {},
   "source": [
    "### Other Approaches to Consider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ac63bb",
   "metadata": {},
   "source": [
    "Instead of feature-engineering in order to create a null (classifier) model, we may instead use a different null model altogether. \n",
    "\n",
    "#### Model 1: (Currently the one Chentian and I think is the most do-able)\n",
    "A simple yet effective model may be to:\n",
    " - Create a test/train split and within the training set compute the word frequencies for ham and spam emails. This would bring rise to 2 average vectors (likely of different dimensions m and n). \n",
    " - Assign a score to each document based on the similarity of its frequency vector to the average vectors after which that document is classified as spam or ham (the threshold for this is decided in the training step).\n",
    " - Measure performance on test set (ROC curve?)\n",
    "\n",
    "#### Model 2:\n",
    "- Honestly, I think we discussed something else but I am so out of it right now I cannot think lol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c93fb",
   "metadata": {},
   "source": [
    "### Some Ideas and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a9d15f",
   "metadata": {},
   "source": [
    "These can be used in either the initial or new approach:\n",
    "- Jackard-Similarity embedding as a document model\n",
    "    - Need to find a way to embed this properly (Sparse SVD or something else?)\n",
    "    - SVD will be different to the TF-IDF SVD\n",
    "- Supervised LDA models \n",
    "    - Check if some library/software already uses this. Should perform considerably better than other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6dfd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9e2aaa1",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1860b53",
   "metadata": {},
   "source": [
    "We need to assign tasks and decide what we're doing each over the next week. But firstly we will need to decide on an approach/hypothesis to test.\n",
    "\n",
    "For the Model 1 approach:\n",
    "- Chentian \n",
    "    - will be working on create the 2 average vectors and implementing the null model.\n",
    "- Mo \n",
    "    - ?\n",
    "- Oliver \n",
    "    - ?\n",
    "- **We need:** \n",
    "    - Topic Models to compare to null model:\n",
    "        - Different LDAs?\n",
    "        - Something else?\n",
    "    - Some performance metric/way to compare the models. \n",
    "        - Someone may need to write code to take in scores from each model that will determine the format of the model outputs.\n",
    "    \n",
    "For the Initial Approach:\n",
    "- Chentian \n",
    "    - ?\n",
    "- Mo\n",
    "    - ?\n",
    "- Oliver \n",
    "    - ?\n",
    "- **We need:**\n",
    "    - Feature engineering\n",
    "    - Topic models to embed classes and extrac those classes as features\n",
    "        - Not sure how to extract feature assigned to each document. May be easy or difficult.\n",
    "    - Performance metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6436dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
